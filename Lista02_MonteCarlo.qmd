---
title: "Lista02"
author: "Andreia, Fernando e Roberto"
format: html
editor: visual
---

## 1) Geração de Números Aleatórios

<!-- -->

##### a. O método Inverse Transform - Exercício 3.3 do livro da Rizzo.

*3.2 The Pareto(a, b) distribution has cdf*

$$F(x) = 1 - (\frac{b}{x})^a, x\geq b\geq 0, a\geq 0$$

*Derive the probability inverse transformation* $F^{-1}(U)$ *and use the inverse transform method to simulate a random sample from the Pareto(2, 2) distribution. Graph the density histogram of the sample with the Pareto(2, 2) density superimposed for comparison.*

##### [Resposta]{.underline}

Para cálculo da transformação inversa, temos que:

$$
u = F(x) = 1 - (\frac{b}{x})^a \Rightarrow 1-u = (\frac{b}{x})^a \Rightarrow {(1-u)}^\frac{1}{a} = \frac{b}{x} \Rightarrow x = \frac{b}{{(1-u)}^\frac{1}{a}} \Rightarrow F^{-1}_x(u) = {b} * {{(1-u)}^\frac{-1}{a}}
$$

Como explicado no Exemplo 3.3 (p.51), $U$ e $1-U$ possuem a mesma distribuição $Uniform(0,1)$, logo é mais simples utilizar ${b} * {{(u)}^\frac{-1}{a}}$.

Por se tratar de função de distribuição acumulada, é necessária derivá-la para encontrar a função densidade de probabilidade, logo:

$$F(x) = 1 - (\frac{b}{x})^a, x\geq b\geq 0, a\geq 0$$

$$
f(x) = F'(x) = 0 - (a)*(b^a*(-1)*x^{-a-1}) \Rightarrow a*b^a*x^{-({a+1})}, x \geq b
$$

```{r}
set.seed(1)
# Valores iniciais dados pelo problema
a <- 2
b <- 2
n <- 2000
u <- runif(n)
x <- b * (u)^(-1/a)
print(summary(x))

hist(x, breaks = 100, prob = TRUE, col = 'lightgreen'
     , main = "Histograma de Amostra Simulada com Dens. Teórica Pareto(2, 2)"
     , xlab = 'x', ylab = 'Densidade')
y <- sort(x)
fy <- a * b^a * y^(- (a + 1))
lines (y, fy, col = 'red', lwd = 1)

```

##### b. O método Acceptance-Rejection - Exercício 3.7 do livro da Rizzo. (Exemplo 3.7 faz isso para Beta(2,2). Para simplificar vocês podem resolver a questão somente para α e β maiores que 1.)

*3.7 Write a function to generate a random sample of size n from the Beta(a, b) distribution by the acceptance-rejection method. Generate a random sample of size 1000 from the Beta(3,2) distribution. Graph the histogram of the sample with the theoretical Beta(3,2) density superimposed.*

##### [Resposta]{.underline}

Vamos calcular a função densidade de probabilidade (PDF) para a distribuição Beta com parâmetros $\alpha = 3$ e $\beta = 2.$

#### Definição Geral da PDF da Distribuição Beta

A função densidade de probabilidade (PDF) da distribuição Beta é dada por: $$f(x; \alpha, \beta) = \frac{x^{\alpha - 1} (1 - x)^{\beta - 1}}{B(\alpha, \beta)}$$

onde $B(\alpha, \beta)$ é a função beta: $B(\alpha, \beta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}$.

Para $\alpha = 3$ e $\beta = 2$ , a PDF se torna: $$ f(x; 3, 2) = \frac{x^{3 - 1} (1 - x)^{2 - 1}}{B(3, 2)} = \frac{x^2 (1 - x)}{B(3, 2)} $$

###### Cálculo da Função Beta B(3, 2)

A função beta para $\alpha = 3$ e $\beta = 2$ é: $B(3, 2) = \frac{\Gamma(3) \Gamma(2)}{\Gamma(3 + 2)}$

Usando as propriedades da função gama: $\Gamma(n) = (n - 1)!$, então, $\Gamma(3) = 2! = 2$, $\Gamma(2) = 1! = 1$, $\Gamma(5) = 4! = 24$

Portanto, $B(3, 2) = \frac{2! \cdot 1!}{4!} = \frac{2 \cdot 1}{24} = \frac{2}{24} = \frac{1}{12}$

Substituindo $B(3, 2) = \frac{1}{12}$ na expressão da PDF: $$
f(x; 3, 2) = \frac{x^2 (1 - x)}{\frac{1}{12}} = x^2 (1 - x) \cdot 12 = 12x^2 (1 - x)
$$

No exercício, para os valores de $\alpha = 3$ e $\beta = 2$, temos uma distribuição unimodal com um pico, assimétrica e levemente incilinada para a direita.

```{r}
function_Beta <- function(n, a, b) 
{ 
  k <- 0
  y <- numeric(n) 
  count <- 0
  while (k < n) 
  {
    u <- runif(1)
    x <- runif(1)
    if (x^(a - 1) * (1 - x)^(b - 1) > u) 
    {
      k <- k + 1
      y[k] <- x
    }
    count <- count + 1
  }
  print(paste("Quantidade de iterações: ", count))
  return(y)
}

y <- function_Beta(1000, a = 3, b = 2)
hist(y, breaks = 50, prob = TRUE, ylim = c(0, 2.5), col='lightgreen')
z <- seq (0, 1, .01)
f.z <- 12 * z^2 * (1-z)
lines (z, f.z, col = 'red', lwd=2)
```

## 2) Integração por Monte Carlo

<!-- -->

##### a. Exercício 5.3 do livro da Rizzo. (Opcional: gera da exponencial truncada ao intervalo \[0;0,5\] e compara a variância.)

*Compute a Monte Carlo estimate* $\hat{\theta}$ of $$
\theta = \int_0^{0.5} e^{-x} \, dx
$$*by sampling from Uniform(0, 0.5), and estimate the variance of* $\hat{\theta}$*. Find another Monte Carlo estimator* $\hat{\theta}^*$ *by sampling from the exponential distribution. Which of the variances (of* $\hat{\theta}$ *and* $\hat{\theta}^*$*) is smaller, and why?*

##### [Resposta]{.underline}

O valor exato da integral é dado por:

$$ \theta = -e^{-0.5} -(-e^{0}) = 1 - e^{-0.5} = 1 - 0.606531 = 0.393469  $$

O estimador de Monte Carlo é dado pela expressão:

$$
\hat{\theta} = (b - a) \int_{a}^{b} g(x) \, dx = \frac{1}{2} \left( \frac{1}{m} \sum_{i=1}^{m} e^{-u} \right),$$

sendo que $u$ é gerado a partir de uma distribuição $Uniform(0, 0.5)$.

```{r}
n <- 5000
u <- runif(n, 0, 0.5)
theta <- 0.5 * mean(exp(-u))
theta
```

```{r}
# Para cada 5.000 amostras da distribuiçào uniforme no intervalo [0, 0.5], vamos 
# calcular o estimador de Monte Carlo usando a função 0.5 * exp(-u), fazendo isso
# 10.000 vezes
estimator <- replicate(10000, expr = {
  u <- runif(n, 0, 0.5)
  theta <- 0.5 * mean(exp(-u))
  theta
})
print(mean(estimator))
c(var(estimator), sd(estimator))
```

Para estimarmos a variância de $\hat{\theta}^*$, vamos utilizar a seguinte expressão:

$$\hat{\theta}^* = \frac{1}{m} \sum_{i=1}^{m} I(v < 0.5)$$, sendo $v$ gerado a partir de uma distribuição $Exponential(1)$.

```{r}
n <- 5000
v <- rexp(n, 1)
theta <- mean(v <= 0.5)
theta
```

```{r}
estimator_1 <- replicate(10000, expr = {
  v <- rexp(n, 1)
  theta <- mean(v <= 0.5)
  theta
})
print(paste("Média do estimador", mean(estimator_1)))
print(c(var(estimator_1), sd(estimator_1)))

print(var(estimator)/var(estimator_1))
```

A variância do estimador $\hat{\theta}$ (baseado na amostragem uniforme) será geralmente maior do que a variância do estimador $\hat{\theta}^*$ (baseado na amostragem exponencial) porque a transformação usada na amostragem exponencial pode reduzir a variabilidade dos valores amostrados, uma vez que é melhor ajustada à forma da função de densidade $e^{-x}$.

Assim, o estimador $\hat{\theta}^*$ terá uma variância menor devido à melhor adequação da amostragem à distribuição exponencial.

##### b. Variáveis Antitéticos: Exercício 5.10 do livro da Rizzo. (Opcional: Trocar esse exercício para 5.9, mas saiba que a função não é monotônica \[pode quebrar em pedaços monotônicos\] e o limite superior é infinito \[precisa fazer alguma transformação de variáveis x-\> 1/x funcionaria\])

*Use Monte Carlo integration with antithetic variables to estimate*

$$ \int_{0}^{1} \frac{e^{-x}}{1 + x^2} \, dx
$$

*and find the approximate reduction in variance as a percentage of the variance without variance reduction.*

##### [Resposta]{.underline}

```{r}
m <- 20000 
monte_carlo <- replicate (2000, expr = 
                   { 
                     u <- runif (m) 
                     mean (exp(-u)/(1 + u^2)) 
                    }
                 )

anti_ethic <- replicate (2000, expr = 
                           { u <- runif (m/2) 
                           x1 <- exp(-u)/(1 + u^2) 
                           x2 <- exp(-(1 -u))/(1 + ((1 -u)^2)) 
                           mean (c (x1, x2)) 
                           }
                         )

print(c(mean(monte_carlo), var(monte_carlo)))
print(c(mean(anti_ethic), var(anti_ethic)))

approx_reduction = 100 * (var (monte_carlo) - var (anti_ethic)) / var (monte_carlo)
print(paste(round(approx_reduction,4), "%"))

```

##### c. Importance Sampling - Exercício 5.14 do livro da Rizzo.

*Obtain a Monte Carlo estimate of* $$\int_{1}^{\infty} \frac{x^2}{\sqrt{2\pi}} e^{-x^2/2} \, dx
 $$ *by importance sampling.*

##### [Resposta]{.underline}

```{r}
n <- 20000
imp_sampl_1 <- replicate(2000, expr = 
                   {
                     x <- sqrt(rchisq(n, 1)) + 1
                     f <- 2 * dnorm(x, 1)
                     g <- x^2 * exp(-x^2/2)/sqrt(2 * pi)
                     mean (g/f)
                   }
)
 
imp_sampl_2 <- replicate(2000, expr = 
                   {
                     x <- rgamma(n, 3/2, 2) + 1
                     f <- dgamma(x - 1, 3/2, 2)
                     g <- x^2 * exp(-x^2/2)/sqrt(2 * pi)
                     mean (g/f)
                   }
)

print(c(mean(imp_sampl_1), mean(imp_sampl_2)))
print(c(var(imp_sampl_1), var(imp_sampl_2)))
print(var(imp_sampl_1)/var(imp_sampl_2))

```

No caso em tela, a 1a. função produz um estimador mais eficiente do que a 2a. função, uma vez que a variância do estimador da 1a. função é menor do que a variância do estimador da 2a. função.

##### d. Stratified Importance Sampling - Exercício 5.15 do livro da Rizzo. (Não esquece de usar os quantís da função importância para definir os intervalos.)

*Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.*

##### [Resposta]{.underline}

O exemplo 5.13 traz a seguinte integral:

$$ \int_{0}^{1} \frac{e^{-x}}{1 + x^2} \, dx $$ com a função importância dada por:

$$ f(x) =  \frac{e^{-x}}{1 - e^{-1}}, 0 \lt x \lt 1,  $$ nos cinco subintervalos: $(j/5, (j + 1)/5), j = 0, 1, . . . , 4.$.

As variáveis no $j^{th}$ subintervalo são geradas a partir da densidade:

$$
\frac{5e^{-x}}{1 - e^{-1}}, \quad \frac{j-1}{5} < x < \frac{j}{5}.
$$

```{r}
set.seed(1)

M <- 10000
k <- 5
m <- M/k
si <- numeric(k)
v <- numeric(k)
g <- function(x) exp(-x)/(1 + x^2)
f <- function(x) ((k * exp(-x))/(1 - exp(-1)))


for(j in 1:k) {
  u <- runif(m, (j - 1)/k, j/k)
  x <- -log(1 - (1 - exp(-1)) * u)
  fg <- g(x)/f(x)
  si[j] <- mean(fg)
  v[j] <- var(fg)
}

print(sum(si))
print(mean(v))
print(sqrt(mean(v)))

```

## 3) Inferência com Monte Carlo

##### a. MSE (EQM): Exercício 6.1 do livro da Rizzo. (aproveite os códigos para a Normal com contaminação)

*Estimate the MSE of the level* $k$ trimmed means for random samples of size 20 generated from a standard Cauchy distribution. (The target parameter $\theta$ is the center or median; the expected value does not exist.) Summarize the estimates of MSE in a table for $k = 1,2,...,9$.

##### [Resposta]{.underline}

```{r}
n <- 20
K <- n/2 - 1 
m <- 1000
mse <- matrix(0, n/2, 2) 
trimmed.mse <- function(n, m, k) 
  {
    tmean <- numeric(m)
    for (i in 1:m) 
    {
      x <- sort(rcauchy(n))
      tmean[i] <- sum(x[(k + 1):(n - k)])/(n - 2 * k)
    }
    mse.est <- mean(tmean^2)
    se.mse <- sqrt(mean((tmean - mean(tmean))^2))/sqrt(m)
    return(c(mse.est, se.mse))
}

for (k in 0:K) 
{
  mse[k + 1, 1:2] <- trimmed.mse(n = n, m = m, k = k)
}

mse <- as.data.frame(cbind(0:K, mse))
names(mse) <- c("k", "t-mean", "se")
print(mse)

```

##### b. Poder de testes: Exercício 6.3 do livro da Rizzo. (aproveite os códigos do Exemplo 6.9)

*Plot the power curves for the t-test in Example 6.9 for sample sizes 10, 20, 30, 40, and 50, but omit the standard error bars. Plot the curves on the same graph, each in a different color or different line type, and include a legend. Comment on the relation between power and sample size.*

##### [Resposta]{.underline}

```{r}
N <- c(10, 20, 30, 40, 50) 
m <- 1000
mu0 <- 500
sigma <- 100
mu <- c(seq(450, 650, 10))
M <- length(mu)
power <- matrix(0, M, 5)
for (j in 1:5) 
{
  n <- N[j]
  for (i in 1:M) 
  {
    mu1 <- mu[i]
    pvalues <- replicate(m, expr = 
    {
      x <- rnorm(n, mean = mu1, sd = sigma)
      ttest <- t.test(x, alternative = "greater", mu = mu0)
      ttest$p.value
    })
    power[i, j] <- mean(pvalues <= 0.05)
  }
}
```

```{r}
plot(mu, power[, 1], type = "l", ylim = range(power), xlab = bquote(mu), ylab = "power")
abline(v = mu0, lty = 3)
abline(h = 0.05, lty = 3)
for (j in 2:5) 
  {
    lines(mu, power[, j], col = j)
  }

legend("bottomright", inset = 0.02, legend = N, col = 1:5, lty = 1)

```

##### c. Níveis de confiança: Exercício 6.4 ou 6.5 do livro da Rizzo

*6.4 Suppose that* $X_1, . . . , X_n$ are a random sample from a from a lognormal dis- tribution with unknown parameters. Construct a 95% confidence interval for the parameter $\mu$. Use a Monte Carlo method to obtain an empirical estimate of the confidence level.

##### [Resposta]{.underline}

```{r}
n <- 30
confid_interv <- replicate(10000, expr = 
  {
    x <- rlnorm(n)
    y <- log(x)
    ybar <- mean(y)
    se <- sd(y)/sqrt(n)
    ybar + se * qnorm(c(0.025, 0.975))
  })
L_confid_interv <- confid_interv[1, ]
U_confid_interv <- confid_interv[2, ]

print(sum(L_confid_interv < 0 & U_confid_interv > 0))
print(mean(L_confid_interv < 0 & U_confid_interv > 0))

  
  
```

# **(Caso decidamos fazer a 6.5)** 

*6.5 Suppose a 95% symmetric* $t$-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the $t$-interval for random samples of \$X\^2(2) data with sample size $n$ = 20. Compare your $t$-interval results with the simulation results in Example 6.4. (The $t$-interval should be more robust to departures from normality than the interval for variance.)

##### [Resposta]{.underline}
